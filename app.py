import streamlit as st
import pandas as pd
import numpy as np
import joblib
from datetime import timedelta
# TH√äM IMPORT N√ÄY: C·∫ßn thi·∫øt cho c√°c l·ªõp t√πy ch·ªânh
from sklearn.base import BaseEstimator, TransformerMixin 

# --- SAO CH√âP C√ÅC ƒê·ªäNH NGHƒ®A L·ªöP T·ª™ FILE HU·∫§N LUY·ªÜN V√ÄO ƒê√ÇY ---

class PreprocessingTransformer(BaseEstimator, TransformerMixin):
    """
    Th·ª±c hi·ªán 2 b∆∞·ªõc:
    1. Chuy·ªÉn ƒë·ªïi c√°c c·ªôt datetime (datetime, sunrise, sunset).
    2. Impute c·ªôt 'severerisk'.
    """
    def fit(self, X, y=None):
        return self
    
    def transform(self, X, y=None):
        X_ = X.copy()
        
        for col in ['datetime', 'sunrise', 'sunset']:
            if col in X_.columns:
                X_[col] = pd.to_datetime(X_[col], errors='coerce')
        
        if 'severerisk' in X_.columns:
            X_['severerisk'] = X_['severerisk'].fillna(10) 
        
        return X_

class FeatureEngineeringTransformer(BaseEstimator, TransformerMixin):
    """
    Th·ª±c hi·ªán t·∫•t c·∫£ c√°c b∆∞·ªõc t·∫°o ƒë·∫∑c tr∆∞ng m·ªõi.
    (L∆∞u √Ω: c√°c tham s·ªë lag_cols, lags... s·∫Ω ƒë∆∞·ª£c n·∫°p t·ª´ file pkl)
    """
    def __init__(self, lag_cols=None, lags=None, roll_cols=None, windows=None):
        self.lag_cols = lag_cols
        self.lags = lags
        self.roll_cols = roll_cols
        self.windows = windows
    
    def fit(self, X, y=None):
        return self
        
    def transform(self, X, y=None):
        X_ = X.copy()
        new_features_df = pd.DataFrame(index=X_.index)
            
        if 'datetime' in X_.columns:
            dt = X_['datetime'].dt
            new_features_df['month_sin'] = np.sin(2 * np.pi * dt.month / 12)
            new_features_df['month_cos'] = np.cos(2 * np.pi * dt.month / 12)
            new_features_df['day_of_year_sin'] = np.sin(2 * np.pi * dt.dayofyear / 365.25)
            new_features_df['day_of_year_cos'] = np.cos(2 * np.pi * dt.dayofyear / 365.25)
            new_features_df['day_of_week_sin'] = np.sin(2 * np.pi * dt.dayofweek / 7)
            new_features_df['day_of_week_cos'] = np.cos(2 * np.pi * dt.dayofweek / 7)
            new_features_df['quarter'] = dt.quarter
            new_features_df['year'] = dt.year

        if self.lag_cols and self.lags:
            for feature in self.lag_cols:
                if feature in X_.columns:
                    for lag in self.lags:
                        new_features_df[f'{feature}_lag{lag}'] = X_[feature].shift(lag)

        if self.roll_cols and self.windows:
            for feature in self.roll_cols:
                 if feature in X_.columns:
                    for w in self.windows:
                        rolling_window = X_[feature].shift(1).rolling(window=w)
                        new_features_df[f'{feature}_roll{w}_mean'] = rolling_window.mean()
                        new_features_df[f'{feature}_roll{w}_std'] = rolling_window.std()
                    
        if 'tempmax' in X_.columns and 'tempmin' in X_.columns:
            new_features_df['temp_range'] = X_['tempmax'] - X_['tempmin']
        if 'humidity' in X_.columns:
            new_features_df['humidity_change'] = X_['humidity'].diff()
        if 'sunrise' in X_.columns and 'sunset' in X_.columns:
            sr = X_['sunrise']
            ss = X_['sunset']
            valid_times = sr.notna() & ss.notna()
            day_length_col = pd.Series(np.nan, index=X_.index, dtype='float64')
            if valid_times.any():
                day_length_col.loc[valid_times] = (ss[valid_times] - sr[valid_times]).dt.total_seconds() / 3600
            new_features_df['day_length_hour'] = day_length_col
        
        X_ = pd.concat([X_, new_features_df], axis=1)
        return X_

class ColumnCleanupTransformer(BaseEstimator, TransformerMixin):
    """
    Lo·∫°i b·ªè c√°c c·ªôt g·ªëc (ƒë√£ ƒë∆∞·ª£c t·∫°o feature) v√† c√°c c·ªôt phi s·ªë.
    """
    def __init__(self, cols_to_drop=None):
        self.cols_to_drop = cols_to_drop
        self.feature_names_ = [] 

    def fit(self, X, y=None):
        # ƒê·∫£m b·∫£o cols_to_drop l√† m·ªôt danh s√°ch
        cols_to_drop_safe = self.cols_to_drop if self.cols_to_drop is not None else []
        X_temp = X.drop(columns=cols_to_drop_safe, errors='ignore')
        self.feature_names_ = X_temp.select_dtypes(include=np.number).columns.tolist()
        return self
        
    def transform(self, X, y=None):
        X_ = X.copy()
        # ƒê·∫£m b·∫£o cols_to_drop l√† m·ªôt danh s√°ch
        cols_to_drop_safe = self.cols_to_drop if self.cols_to_drop is not None else []
        X_ = X_.drop(columns=cols_to_drop_safe, errors='ignore')
        
        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p c√°c c·ªôt b·ªã thi·∫øu (v√≠ d·ª•: khi d·ª± ƒëo√°n tr√™n d·ªØ li·ªáu m·ªõi)
        # Ch·ªâ gi·ªØ l·∫°i c√°c c·ªôt ƒë√£ th·∫•y l√∫c fit, v√† th√™m c√°c c·ªôt b·ªã thi·∫øu (n·∫øu c√≥) v·ªõi gi√° tr·ªã np.nan
        X_out = pd.DataFrame(index=X_.index)
        for col in self.feature_names_:
            if col in X_.columns:
                X_out[col] = X_[col]
            else:
                # C·ªôt n√†y c√≥ l√∫c fit nh∆∞ng kh√¥ng c√≥ l√∫c transform
                X_out[col] = np.nan 
                
        return X_out[self.feature_names_] # ƒê·∫£m b·∫£o ƒë√∫ng th·ª© t·ª± c·ªôt
        
    def get_feature_names_out(self, input_features=None):
         return np.array(self.feature_names_)

# --- K·∫æT TH√öC PH·∫¶N SAO CH√âP L·ªöP ---


# --- 1. C·∫•u h√¨nh trang (Gi·ªØ nguy√™n) ---
st.set_page_config(
    page_title="D·ª± ƒëo√°n th·ªùi ti·∫øt H√† N·ªôi",
    page_icon="üå§Ô∏è",
    layout="wide"
)

# --- 2. H·∫±ng s·ªë (Gi·ªØ nguy√™n) ---
MODEL_PATH = 'full_weather_pipeline.pkl'
DATA_URL = 'https://raw.githubusercontent.com/DanhBitoo/HanoiDaily-temperature/refs/heads/main/Hanoi%20Daily.csv'
HORIZON = 5 

# --- 3. H√†m t·∫£i m√¥ h√¨nh (Gi·ªØ nguy√™n) ---
@st.cache_resource
def load_model(path):
    """
    T·∫£i m√¥ h√¨nh pipeline t·ª´ file .pkl.
    S·ª≠ d·ª•ng cache_resource ƒë·ªÉ ch·ªâ t·∫£i m√¥ h√¨nh m·ªôt l·∫ßn.
    """
    try:
        model = joblib.load(path)
        return model
    except FileNotFoundError:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y file m√¥ h√¨nh t·∫°i '{path}'.")
        st.error("Vui l√≤ng ƒë·∫£m b·∫£o file `full_weather_pipeline.pkl` n·∫±m c√πng th∆∞ m·ª•c v·ªõi `app.py`.")
        return None
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i m√¥ h√¨nh: {e}")
        st.exception(e) # In ra traceback ƒë·∫ßy ƒë·ªß
        return None

# --- 4. H√†m t·∫£i d·ªØ li·ªáu (Gi·ªØ nguy√™n) ---
@st.cache_data
def load_data(url):
    """
    T·∫£i d·ªØ li·ªáu l·ªãch s·ª≠ t·ª´ URL.
    S·ª≠ d·ª•ng cache_data ƒë·ªÉ ch·ªâ t·∫£i d·ªØ li·ªáu m·ªôt l·∫ßn.
    """
    try:
        df = pd.read_csv(url)
        return df
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu t·ª´ URL: {e}")
        return None

# --- 5. Giao di·ªán ch√≠nh c·ªßa ·ª©ng d·ª•ng (Gi·ªØ nguy√™n) ---
def main():
    st.title("üå§Ô∏è ·ª®ng d·ª•ng d·ª± ƒëo√°n nhi·ªát ƒë·ªô 5 ng√†y t·ªõi t·∫°i H√† N·ªôi")
    st.write("·ª®ng d·ª•ng n√†y s·ª≠ d·ª•ng m√¥ h√¨nh Ridge Regression ƒë√£ hu·∫•n luy·ªán (bao g·ªìm to√†n b·ªô pipeline x·ª≠ l√Ω) ƒë·ªÉ d·ª± ƒëo√°n nhi·ªát ƒë·ªô.")

    # T·∫£i m√¥ h√¨nh
    model = load_model(MODEL_PATH)
    if model is None:
        st.stop() 

    # T·∫£i d·ªØ li·ªáu
    df_history = load_data(DATA_URL)
    if df_history is None:
        st.stop() 

    # Hi·ªÉn th·ªã th√¥ng tin d·ªØ li·ªáu
    st.subheader("D·ªØ li·ªáu l·ªãch s·ª≠ (m·ªõi nh·∫•t)")
    st.write(f"ƒê√£ t·∫£i {len(df_history)} ng√†y d·ªØ li·ªáu l·ªãch s·ª≠ t·ª´ GitHub.")
    
    try:
        last_date_str = df_history['datetime'].iloc[-1]
        last_date = pd.to_datetime(last_date_str)
        st.info(f"D·ªØ li·ªáu l·ªãch s·ª≠ m·ªõi nh·∫•t l√† c·ªßa ng√†y: **{last_date.strftime('%Y-%m-%d')}**")
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω c·ªôt 'datetime': {e}")
        st.dataframe(df_history.tail())
        st.stop()
        
    st.dataframe(df_history.tail())

    # N√∫t d·ª± ƒëo√°n
    st.subheader("B·∫Øt ƒë·∫ßu d·ª± ƒëo√°n")
    if st.button(f"D·ª± ƒëo√°n {HORIZON} ng√†y ti·∫øp theo", type="primary"):
        
        with st.spinner("ƒêang ch·∫°y pipeline... (t√≠nh to√°n cyclical, lags, rolling, scaling... v√† d·ª± ƒëo√°n)"):
            try:
                # ƒê∆∞a TO√ÄN B·ªò d·ªØ li·ªáu l·ªãch s·ª≠ th√¥ v√†o h√†m predict.
                all_predictions = model.predict(df_history)
                
                # D·ª± ƒëo√°n ch√∫ng ta c·∫ßn n·∫±m ·ªü H√ÄNG CU·ªêI C√ôNG
                future_predictions = all_predictions[-1]

                st.success("D·ª± ƒëo√°n ho√†n t·∫•t!")

                # T·∫°o c√°c ng√†y trong t∆∞∆°ng lai
                future_dates = [last_date + timedelta(days=i) for i in range(1, HORIZON + 1)]
                
                # T·∫°o DataFrame k·∫øt qu·∫£
                df_results = pd.DataFrame({
                    'Ng√†y d·ª± ƒëo√°n': future_dates,
                    f'Nhi·ªát ƒë·ªô d·ª± ƒëo√°n (¬∞C)': future_predictions
                })
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                st.subheader("K·∫øt qu·∫£ d·ª± ƒëo√°n")
                
                df_results_display = df_results.copy()
                df_results_display['Ng√†y d·ª± ƒëo√°n'] = df_results_display['Ng√†y d·ª± ƒëo√°n'].dt.strftime('%Y-%m-%d')
                
                st.dataframe(df_results_display, use_container_width=True)

                # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
                st.subheader("Bi·ªÉu ƒë·ªì d·ª± ƒëo√°n")
                
                chart_data = df_results.set_index('Ng√†y d·ª± ƒëo√°n')
                st.line_chart(chart_data)

            except Exception as e:
                st.error(f"ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh d·ª± ƒëo√°n: {e}")
                st.exception(e) 

# Ch·∫°y ·ª©ng d·ª•ng
if __name__ == "__main__":
    main()

